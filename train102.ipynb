{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import time\n",
    "import pickle\n",
    "from options.train_options import TrainOptions\n",
    "from data import CreateDataLoader\n",
    "from models import create_model\n",
    "from util.visualizer import Visualizer\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdirs(paths):\n",
    "    if isinstance(paths, list) and not isinstance(paths, str):\n",
    "        for path in paths:\n",
    "            mkdir(path)\n",
    "    else:\n",
    "        mkdir(paths)\n",
    "def mkdir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = TrainOptions().parse()\n",
    "opt.dataroot='/opt/data/private/生成器测试/datasets/petct102'\n",
    "opt.model = 'pGAN'\n",
    "opt.name = 'AttU_Net'\n",
    "\n",
    "opt.which_model_netG = 'AttU_Net'\n",
    "\n",
    "opt.lr  = 0.0002\n",
    "opt.lr2 = 0.0002\n",
    "\n",
    "opt.batchSize = 4\n",
    "opt.which_direction =  'BtoA'\n",
    "opt.lambda_A  = 100\n",
    "opt.lambda_B = 0\n",
    "opt.dataset_mode = 'aligned'\n",
    "opt.pool_size = 0\n",
    "opt.output_nc  = 1 \n",
    "opt.input_nc  = 3\n",
    "opt.loadSize =256\n",
    "opt.niter  = 50\n",
    "opt.niter_decay  = 50\n",
    "opt.save_epoch_freq  = 25\n",
    "opt.lambda_vgg  = 100 \n",
    "opt.checkpoints_dir  = 'checkpoints/'\n",
    "opt.pre_trained_transformer = 1\n",
    "opt.gpu_ids = [0]\n",
    "opt.norm=\"batch\"\n",
    "opt.lambda_gdl=0\n",
    "opt.lambda_str=0\n",
    "\n",
    "opt.display_server = \"http://114.212.200.248\"\n",
    "opt.display_port = 25809\n",
    "\n",
    "opt.training =True\n",
    "\n",
    "if len(opt.gpu_ids) > 0:\n",
    "    torch.cuda.set_device(opt.gpu_ids[0])\n",
    "\n",
    "args = vars(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vars(opt)\n",
    "\n",
    "print('------------ Options -------------')\n",
    "for k, v in sorted(args.items()):\n",
    "    print('%s: %s' % (str(k), str(v)))\n",
    "print('-------------- End ----------------')\n",
    "\n",
    "# save to the disk\n",
    "expr_dir = os.path.join(opt.checkpoints_dir, opt.name)\n",
    "mkdirs(expr_dir)\n",
    "file_name = os.path.join(expr_dir, 'opt.txt')\n",
    "with open(file_name, 'wt') as opt_file:\n",
    "    opt_file.write('------------ Options -------------\\n')\n",
    "    for k, v in sorted(args.items()):\n",
    "        opt_file.write('%s: %s\\n' % (str(k), str(v)))\n",
    "    opt_file.write('-------------- End ----------------\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = create_model(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "train_size = 0\n",
    "val_size = 0\n",
    "number = 102\n",
    "batch_size = 20\n",
    "samples = np.arange(number-number % batch_size+1)\n",
    "for i in range(1, len(samples), batch_size):\n",
    "    with open('/opt/data/private/生成器测试/datasets/petct102/train/train_{}.pkl'.format(i), 'rb') as f:\n",
    "        data_ct = pickle.load(f)\n",
    "        print(data_ct.shape)\n",
    "        train_size+= data_ct.shape[2]\n",
    "print(train_size)\n",
    "\n",
    "for i in range(1, len(samples), batch_size):\n",
    "    with open('/opt/data/private/生成器测试/datasets/petct102/val/val_{}.pkl'.format(i), 'rb') as f:\n",
    "        data_ct = pickle.load(f)\n",
    "        print(data_ct.shape)\n",
    "        val_size+= data_ct.shape[2]\n",
    "print(val_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = opt.input_nc \n",
    "dataset_size = train_size-(k-1)*(number//batch_size)\n",
    "dataset_size_val = val_size-(k-1)*(number//batch_size)\n",
    "samples = np.arange(number-number % batch_size+1)\n",
    "def print_log(logger,message):\n",
    "    print(message, flush=True)\n",
    "    if logger:\n",
    "        logger.write(str(message) + '\\n')\n",
    "\n",
    "##logger ##\n",
    "save_dir = os.path.join(opt.checkpoints_dir, opt.name)\n",
    "logger = open(os.path.join(save_dir, 'log.txt'), 'w+')\n",
    "print_log(logger,opt.name)\n",
    "logger.close()\n",
    "\n",
    "L1_avg=np.zeros([opt.niter + opt.niter_decay,dataset_size_val])      \n",
    "psnr_avg=np.zeros([opt.niter + opt.niter_decay,dataset_size_val]) \n",
    "\n",
    "visualizer = Visualizer(opt)\n",
    "total_steps = 0\n",
    "#Starts training\n",
    "for epoch in range(opt.epoch_count, opt.niter + opt.niter_decay + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    iter_data_time = time.time()\n",
    "    epoch_iter = 0\n",
    "\n",
    "    # import tracemalloc \n",
    "    # tracemalloc.start()\n",
    "    \n",
    "    #Training step\n",
    "    opt.phase='train'\n",
    "    opt.batchSize = 4\n",
    "    for j in range(1, len(samples), batch_size):\n",
    "        data_loader = CreateDataLoader(opt,j)\n",
    "        dataset = data_loader.load_data()\n",
    "        print('Training images = %d' % dataset_size)  \n",
    "    \n",
    "        for i, data in enumerate(dataset):\n",
    "            iter_start_time = time.time()\n",
    "            if total_steps % opt.print_freq == 0:\n",
    "                t_data = iter_start_time - iter_data_time\n",
    "            visualizer.reset()\n",
    "            total_steps += opt.batchSize\n",
    "            epoch_iter += opt.batchSize\n",
    "\n",
    "            model.set_input(data)\n",
    "            model.optimize_parameters()\n",
    "            \n",
    "            #Save current images (real_A, real_B, fake_B)\n",
    "            if  epoch_iter % opt.display_freq == 0:\n",
    "                save_result = total_steps % opt.update_html_freq == 0\n",
    "                #print(model.get_current_visuals())\n",
    "                visualizer.display_current_results(model.get_current_visuals(), epoch , save_result)\n",
    "            #Save current errors   \n",
    "            if total_steps % opt.print_freq == 0:\n",
    "                errors = model.get_current_errors()\n",
    "                t = (time.time() - iter_start_time) / opt.batchSize\n",
    "                visualizer.print_current_errors(epoch, epoch_iter, errors, t, t_data)\n",
    "\n",
    "                if opt.display_id > 0:\n",
    "                    visualizer.plot_current_errors(epoch, float(epoch_iter) / dataset_size, opt, errors)\n",
    "            #Save model based on the number of iterations\n",
    "            if total_steps % opt.save_latest_freq == 0:\n",
    "                print('saving the latest model (epoch %d, total_steps %d)' %\n",
    "                      (epoch, total_steps))\n",
    "                model.save('latest')\n",
    "    \n",
    "            iter_data_time = time.time()\n",
    "\n",
    "    #         current_mem, peak_mem = tracemalloc.get_traced_memory()\n",
    "    #         print(f\"Current memory usage is {current_mem / 10**6}MB\")\n",
    "    #         print(f\"Peak was {peak_mem / 10**6}MB\")\n",
    "    # tracemalloc.stop()\n",
    "    n2=0\n",
    "    if epoch % opt.save_epoch_freq == 0:\n",
    "        logger = open(os.path.join(save_dir, 'log.txt'), 'a')\n",
    "        print(opt.dataset_mode)\n",
    "        opt.phase='val'\n",
    "        opt.batchSize = 1\n",
    "        for j in range(1, len(samples), batch_size):\n",
    "            data_loader_val = CreateDataLoader(opt,j)\n",
    "            dataset_val = data_loader_val.load_data()\n",
    "            n1 = len(data_loader_val)\n",
    "            print('Validation images = %d' % dataset_size) \n",
    "            for i, data_val in enumerate(dataset_val):  \n",
    "\t\t    \n",
    "                model.set_input(data_val)      \t\t    \n",
    "                model.test()  \n",
    "\n",
    "                fake_im=model.fake_B.cpu().data.numpy()       \t\t    \n",
    "                real_im=model.real_B.cpu().data.numpy()        \t\t    \n",
    "                real_im=real_im*0.5+0.5      \t\t    \n",
    "                fake_im=fake_im*0.5+0.5   \t\t    \n",
    "\n",
    "                \n",
    "                if real_im.max() <= 0:\n",
    "                    continue\n",
    "                L1_avg[epoch-1,n2+i]=abs(fake_im-real_im).mean()\n",
    "                psnr_avg[epoch-1,n2+i]=psnr(fake_im,real_im)\n",
    "\n",
    "            n2 = n2 + n1\n",
    "        l1_avg_loss = np.mean(L1_avg[epoch-1])               \n",
    "        mean_psnr = np.mean(psnr_avg[epoch-1])               \n",
    "        std_psnr = np.std(psnr_avg[epoch-1]) \n",
    "\n",
    "              \n",
    "        print_log(logger,'Epoch %3d   l1_avg_loss: %.5f   mean_psnr: %.3f  std_psnr:%.3f  ' % \\\n",
    "        (epoch, l1_avg_loss, mean_psnr,std_psnr))   \n",
    "\n",
    "        print_log(logger,'')\n",
    "        logger.close()\n",
    "        \n",
    "        print('saving the model at the end of epoch %d, iters %d' %(epoch, total_steps))        \t\t    \n",
    "        model.save('latest')     \t\t   \n",
    "        model.save(epoch)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('End of epoch %d / %d \\t Time Taken: %d sec' %\n",
    "                (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n",
    "    model.update_learning_rate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.netG)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
