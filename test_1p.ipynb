{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import pickle\n",
    "from options.test_options import TestOptions\n",
    "from data import CreateDataLoader2\n",
    "from models import create_model\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt \n",
    "import cv2\n",
    "import SimpleITK as sitk\n",
    "from skimage import filters, exposure\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第102个影像 axial 已处理完成！\n",
      "这个影像的CTmax:1261.0,PETmiddle10854.66015625,PETmax30637.451684571417\n"
     ]
    }
   ],
   "source": [
    "def resample_image(ori_img, target_img, target_size=(256, 256)):\n",
    "    target_Size = (*target_size, ori_img.GetSize()[2])  # 目标图像大小  [x,y,z] ,在z轴上保持原始图像的大小  \n",
    "    target_Spacing = (2.34375, 2.34375, 4.0)            # 目标的体素块尺寸    [x,y,z] #CT尺寸的两倍 1.171875*2=2.34375 4不变\n",
    "    target_origin = target_img.GetOrigin()              # 目标的起点 [x,y,z]\n",
    "    target_direction = target_img.GetDirection()   \n",
    " \n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetReferenceImage(ori_img)  # 需要重新采样的目标图像\n",
    "    resampler.SetSize(target_Size)\t\t# 目标图像大小\n",
    "    resampler.SetOutputOrigin(target_origin)\n",
    "    resampler.SetOutputDirection(target_direction)\n",
    "    resampler.SetOutputSpacing(target_Spacing)\n",
    "    resampler.SetTransform(sitk.Transform())\n",
    "    \n",
    "    resampler.SetOutputPixelType(sitk.sitkFloat32)\n",
    "    resampler.SetInterpolator(sitk.sitkBSpline)#多分辨率B样条算法 基于B样条的非刚性配准\n",
    "\n",
    "    return resampler.Execute(ori_img)\n",
    "\n",
    "def median_image_itk(ori_img , radius = 1):\n",
    "    sitk_median = sitk.MedianImageFilter()\n",
    "    sitk_median.SetRadius(radius)\n",
    "    img = sitk_median.Execute(ori_img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def postprocess(img, minn , top=99.95 , y_axis = 0.90 ,ct=False): \n",
    "    #99.95%去掉离群点\n",
    "    img = sitk.GetArrayFromImage(img)\n",
    "    maxx = np.percentile(img, top) \n",
    "    img = img.clip(minn,maxx)\n",
    "\n",
    "    if ct:\n",
    "        img = 2 * (img - minn) / (maxx - minn) - 1\n",
    "        return img,maxx\n",
    "\n",
    "    #算分段阈值\n",
    "    middle = filters.threshold_otsu(img,nbins=int(maxx))\n",
    "\n",
    "    imgMinMid = np.clip(img, minn, middle)\n",
    "    imgMinMid = (imgMinMid - minn)/(middle-minn)*y_axis*2-1\n",
    "    \n",
    "    imgMidMax = np.clip(img, middle, maxx)\n",
    "    imgMidMax = ((imgMidMax - middle)/(maxx-middle)*(1-y_axis) + y_axis)*2-1\n",
    "    \n",
    "    img = (img>=middle)*imgMidMax  + (img<middle)*imgMinMid\n",
    "    return img,middle,maxx\n",
    "\n",
    "def testpkl(path,path2,direction ='axial'):\n",
    "    i = 102\n",
    "    merge=False\n",
    "\n",
    "    NifitmPathCT = path + r\"CT/%04d.nii.gz\" % i\n",
    "    NifitmPathPET = path + r\"PET/%04d.nii.gz\" % i\n",
    "\n",
    "    sitkImageCT = sitk.ReadImage(NifitmPathCT)\n",
    "    sitkImagePET = sitk.ReadImage(NifitmPathPET)\n",
    "\n",
    "    #重采样\n",
    "    resample_PET = resample_image(sitkImagePET,sitkImageCT)\n",
    "    resample_CT  = resample_image(sitkImageCT,sitkImageCT)\n",
    "\n",
    "    #归一化，并记下最大值\n",
    "    CT,CTmax = postprocess(resample_CT, minn =-1024 , top=99.95 , y_axis = 0.90 ,ct=True)\n",
    "    PET,PETmiddle,PETmax = postprocess(resample_PET, minn =0 , top=99.95 , y_axis = 0.90 )\n",
    "\n",
    "    CT = np.transpose(CT, (1, 2, 0))\n",
    "    PET = np.transpose(PET, (1, 2, 0))\n",
    "\n",
    "    print(\"第{}个影像 {} 已处理完成！\".format(i,direction))   \n",
    "\n",
    "    with open(path2+'/test.pkl', 'wb') as f:\n",
    "        pickle.dump(CT .astype(np.float32), f)\n",
    "        pickle.dump(PET.astype(np.float32), f)\n",
    "    f.close()\n",
    "    return CTmax, PETmiddle,PETmax\n",
    "    \n",
    "path = '/opt/data/private/pGAN-cGAN-ct-pet-pkl/petct/'\n",
    "for dire in['axial']:#['axial','coronal','sagittal']\n",
    "    path2= '/opt/data/private/PET生成CT/pictures/'+'/test'#'/opt/data/private/PET生成CT/pictures/'+dire+'/test'\n",
    "    if not os.path.exists(path2):\n",
    "        os.makedirs(path2)\n",
    "    CTmax, PETmiddle,PETmax = testpkl(path,path2,direction = dire)\n",
    "print(f\"这个影像的CTmax:{CTmax},PETmiddle{PETmiddle},PETmax{PETmax}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def back_images(i,visuals, image_path,  CTmax,aspect_ratio=1.0):\n",
    "    image_dir = \"/opt/data/private/PET生成CT/pictures/results\"\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)\n",
    "    name = \"petct102\"\n",
    "\n",
    "    for label, im in visuals.items():\n",
    "        if label =='real_B':\n",
    "            im_mapped = ((im - 0) / (255 - 0)) * (CTmax - -1024) + -1024\n",
    "            im= np.clip(im_mapped, -1024, CTmax)\n",
    "        elif label=='fake_B':\n",
    "            im_mapped = ((im - 0) / (255 - 0)) * (CTmax - -1024) + -1024\n",
    "            im_faked= np.clip(im_mapped, -1024, CTmax)\n",
    "\n",
    "    return im,im_faked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = TestOptions().parse()\n",
    "opt.dataroot='/opt/data/private/PET生成CT/pictures'\n",
    "opt.model = 'pGAN'\n",
    "opt.name = 'FCT_res'\n",
    "\n",
    "opt.which_model_netG = 'FCT_res'\n",
    "\n",
    "opt.which_direction =  'BtoA'\n",
    "opt.phase ='test' \n",
    "opt.batchSize = 1\n",
    "opt.output_nc =1 \n",
    "opt.input_nc = 3\n",
    "opt.how_many = 800\n",
    "opt.gpu_ids = [0]\n",
    "opt.norm=\"batch\"\n",
    "\n",
    "opt.results_dir = 'pictures/'\n",
    "opt.checkpoints_dir ='checkpoints/'\n",
    "opt.dataset_mode = 'aligned'\n",
    "opt.display_server = \"http://114.212.200.248\"\n",
    "opt.display_port = 25809\n",
    "\n",
    "opt.nThreads = 1   # test code only supports nThreads = 1\n",
    "opt.batchSize = 1  # test code only supports batchSize = 1\n",
    "opt.serial_batches = True  # no shuffle\n",
    "\n",
    "if len(opt.gpu_ids) > 0:\n",
    "    torch.cuda.set_device(opt.gpu_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pGAN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization method [normal]\n",
      "---------- Networks initialized -------------\n",
      "FCTGenerator2(\n",
      "  (model_1): Sequential(\n",
      "    (0): residualUnit(\n",
      "      (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (convX): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bnX): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (model_2): Sequential(\n",
      "    (0): residualUnit(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (convX): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bnX): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (model_3): Sequential(\n",
      "    (0): residualUnit(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (convX): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bnX): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (model_4): Sequential(\n",
      "    (0): Transformer2(\n",
      "      (attention_output): Attention(\n",
      "        (conv_q): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=256)\n",
      "        (layernorm_q): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv_k): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "        (layernorm_k): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv_v): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "        (layernorm_v): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (wide_focus): Wide_Focus(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(2, 2))\n",
      "        (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(3, 3))\n",
      "        (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "      )\n",
      "      (resnet): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (model_5): Sequential(\n",
      "    (0): Transformer2(\n",
      "      (attention_output): Attention(\n",
      "        (conv_q): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=256)\n",
      "        (layernorm_q): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv_k): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "        (layernorm_k): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv_v): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "        (layernorm_v): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (wide_focus): Wide_Focus(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(2, 2))\n",
      "        (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(3, 3))\n",
      "        (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "      )\n",
      "      (resnet): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (model_6): Sequential(\n",
      "    (0): Transformer2(\n",
      "      (attention_output): Attention(\n",
      "        (conv_q): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=256)\n",
      "        (layernorm_q): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv_k): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "        (layernorm_k): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv_v): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "        (layernorm_v): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (wide_focus): Wide_Focus(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(2, 2))\n",
      "        (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(3, 3))\n",
      "        (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "      )\n",
      "      (resnet): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (model_7): Sequential(\n",
      "    (0): Transformer2(\n",
      "      (attention_output): Attention(\n",
      "        (conv_q): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=256)\n",
      "        (layernorm_q): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv_k): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "        (layernorm_k): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv_v): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "        (layernorm_v): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (wide_focus): Wide_Focus(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(2, 2))\n",
      "        (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(3, 3))\n",
      "        (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "      )\n",
      "      (resnet): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (model_8): Sequential(\n",
      "    (0): Transformer2(\n",
      "      (attention_output): Attention(\n",
      "        (conv_q): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=256)\n",
      "        (layernorm_q): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv_k): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "        (layernorm_k): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv_v): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "        (layernorm_v): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (wide_focus): Wide_Focus(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(2, 2))\n",
      "        (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(3, 3))\n",
      "        (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "      )\n",
      "      (resnet): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (model_9): Sequential(\n",
      "    (0): Transformer2(\n",
      "      (attention_output): Attention(\n",
      "        (conv_q): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=256)\n",
      "        (layernorm_q): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv_k): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "        (layernorm_k): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv_v): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "        (layernorm_v): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (wide_focus): Wide_Focus(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(2, 2))\n",
      "        (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(3, 3))\n",
      "        (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "      )\n",
      "      (resnet): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (model_10): Sequential(\n",
      "    (0): Transformer2(\n",
      "      (attention_output): Attention(\n",
      "        (conv_q): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=256)\n",
      "        (layernorm_q): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv_k): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "        (layernorm_k): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv_v): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "        (layernorm_v): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (wide_focus): Wide_Focus(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(2, 2))\n",
      "        (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(3, 3))\n",
      "        (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "      )\n",
      "      (resnet): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (model_11): Sequential(\n",
      "    (0): Transformer2(\n",
      "      (attention_output): Attention(\n",
      "        (conv_q): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=256)\n",
      "        (layernorm_q): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv_k): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "        (layernorm_k): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv_v): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "        (layernorm_v): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (wide_focus): Wide_Focus(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(2, 2))\n",
      "        (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(3, 3))\n",
      "        (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "      )\n",
      "      (resnet): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (model_12): Sequential(\n",
      "    (0): Transformer2(\n",
      "      (attention_output): Attention(\n",
      "        (conv_q): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=256)\n",
      "        (layernorm_q): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv_k): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "        (layernorm_k): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv_v): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "        (layernorm_v): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (wide_focus): Wide_Focus(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(2, 2))\n",
      "        (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(3, 3))\n",
      "        (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "      )\n",
      "      (resnet): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (model_13): Sequential(\n",
      "    (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (model_14): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (model_15): Sequential(\n",
      "    (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 41189889\n",
      "-----------------------------------------------\n",
      "model [pGAN] was created\n",
      "0000: process image... ['/opt/data/private/PET生成CT/pictures0']\n",
      "0001: process image... ['/opt/data/private/PET生成CT/pictures1']\n",
      "0002: process image... ['/opt/data/private/PET生成CT/pictures2']\n",
      "0003: process image... ['/opt/data/private/PET生成CT/pictures3']\n",
      "0004: process image... ['/opt/data/private/PET生成CT/pictures4']\n",
      "0005: process image... ['/opt/data/private/PET生成CT/pictures5']\n",
      "0006: process image... ['/opt/data/private/PET生成CT/pictures6']\n",
      "0007: process image... ['/opt/data/private/PET生成CT/pictures7']\n",
      "0008: process image... ['/opt/data/private/PET生成CT/pictures8']\n",
      "0009: process image... ['/opt/data/private/PET生成CT/pictures9']\n",
      "0010: process image... ['/opt/data/private/PET生成CT/pictures10']\n",
      "0011: process image... ['/opt/data/private/PET生成CT/pictures11']\n",
      "0012: process image... ['/opt/data/private/PET生成CT/pictures12']\n",
      "0013: process image... ['/opt/data/private/PET生成CT/pictures13']\n",
      "0014: process image... ['/opt/data/private/PET生成CT/pictures14']\n",
      "0015: process image... ['/opt/data/private/PET生成CT/pictures15']\n",
      "0016: process image... ['/opt/data/private/PET生成CT/pictures16']\n",
      "0017: process image... ['/opt/data/private/PET生成CT/pictures17']\n",
      "0018: process image... ['/opt/data/private/PET生成CT/pictures18']\n",
      "0019: process image... ['/opt/data/private/PET生成CT/pictures19']\n",
      "0020: process image... ['/opt/data/private/PET生成CT/pictures20']\n",
      "0021: process image... ['/opt/data/private/PET生成CT/pictures21']\n",
      "0022: process image... ['/opt/data/private/PET生成CT/pictures22']\n",
      "0023: process image... ['/opt/data/private/PET生成CT/pictures23']\n",
      "0024: process image... ['/opt/data/private/PET生成CT/pictures24']\n",
      "0025: process image... ['/opt/data/private/PET生成CT/pictures25']\n",
      "0026: process image... ['/opt/data/private/PET生成CT/pictures26']\n",
      "0027: process image... ['/opt/data/private/PET生成CT/pictures27']\n",
      "0028: process image... ['/opt/data/private/PET生成CT/pictures28']\n",
      "0029: process image... ['/opt/data/private/PET生成CT/pictures29']\n",
      "0030: process image... ['/opt/data/private/PET生成CT/pictures30']\n",
      "0031: process image... ['/opt/data/private/PET生成CT/pictures31']\n",
      "0032: process image... ['/opt/data/private/PET生成CT/pictures32']\n",
      "0033: process image... ['/opt/data/private/PET生成CT/pictures33']\n",
      "0034: process image... ['/opt/data/private/PET生成CT/pictures34']\n",
      "0035: process image... ['/opt/data/private/PET生成CT/pictures35']\n",
      "0036: process image... ['/opt/data/private/PET生成CT/pictures36']\n",
      "0037: process image... ['/opt/data/private/PET生成CT/pictures37']\n",
      "0038: process image... ['/opt/data/private/PET生成CT/pictures38']\n",
      "0039: process image... ['/opt/data/private/PET生成CT/pictures39']\n",
      "0040: process image... ['/opt/data/private/PET生成CT/pictures40']\n",
      "0041: process image... ['/opt/data/private/PET生成CT/pictures41']\n",
      "0042: process image... ['/opt/data/private/PET生成CT/pictures42']\n",
      "0043: process image... ['/opt/data/private/PET生成CT/pictures43']\n",
      "0044: process image... ['/opt/data/private/PET生成CT/pictures44']\n",
      "0045: process image... ['/opt/data/private/PET生成CT/pictures45']\n",
      "0046: process image... ['/opt/data/private/PET生成CT/pictures46']\n",
      "0047: process image... ['/opt/data/private/PET生成CT/pictures47']\n",
      "0048: process image... ['/opt/data/private/PET生成CT/pictures48']\n",
      "0049: process image... ['/opt/data/private/PET生成CT/pictures49']\n",
      "0050: process image... ['/opt/data/private/PET生成CT/pictures50']\n",
      "0051: process image... ['/opt/data/private/PET生成CT/pictures51']\n",
      "0052: process image... ['/opt/data/private/PET生成CT/pictures52']\n",
      "0053: process image... ['/opt/data/private/PET生成CT/pictures53']\n",
      "0054: process image... ['/opt/data/private/PET生成CT/pictures54']\n",
      "0055: process image... ['/opt/data/private/PET生成CT/pictures55']\n",
      "0056: process image... ['/opt/data/private/PET生成CT/pictures56']\n",
      "0057: process image... ['/opt/data/private/PET生成CT/pictures57']\n",
      "0058: process image... ['/opt/data/private/PET生成CT/pictures58']\n",
      "0059: process image... ['/opt/data/private/PET生成CT/pictures59']\n",
      "0060: process image... ['/opt/data/private/PET生成CT/pictures60']\n",
      "0061: process image... ['/opt/data/private/PET生成CT/pictures61']\n",
      "0062: process image... ['/opt/data/private/PET生成CT/pictures62']\n",
      "0063: process image... ['/opt/data/private/PET生成CT/pictures63']\n",
      "0064: process image... ['/opt/data/private/PET生成CT/pictures64']\n",
      "0065: process image... ['/opt/data/private/PET生成CT/pictures65']\n",
      "0066: process image... ['/opt/data/private/PET生成CT/pictures66']\n",
      "0067: process image... ['/opt/data/private/PET生成CT/pictures67']\n",
      "0068: process image... ['/opt/data/private/PET生成CT/pictures68']\n",
      "0069: process image... ['/opt/data/private/PET生成CT/pictures69']\n",
      "0070: process image... ['/opt/data/private/PET生成CT/pictures70']\n",
      "0071: process image... ['/opt/data/private/PET生成CT/pictures71']\n",
      "0072: process image... ['/opt/data/private/PET生成CT/pictures72']\n",
      "0073: process image... ['/opt/data/private/PET生成CT/pictures73']\n",
      "0074: process image... ['/opt/data/private/PET生成CT/pictures74']\n",
      "0075: process image... ['/opt/data/private/PET生成CT/pictures75']\n",
      "0076: process image... ['/opt/data/private/PET生成CT/pictures76']\n",
      "0077: process image... ['/opt/data/private/PET生成CT/pictures77']\n",
      "0078: process image... ['/opt/data/private/PET生成CT/pictures78']\n",
      "0079: process image... ['/opt/data/private/PET生成CT/pictures79']\n",
      "0080: process image... ['/opt/data/private/PET生成CT/pictures80']\n",
      "0081: process image... ['/opt/data/private/PET生成CT/pictures81']\n",
      "0082: process image... ['/opt/data/private/PET生成CT/pictures82']\n",
      "0083: process image... ['/opt/data/private/PET生成CT/pictures83']\n",
      "0084: process image... ['/opt/data/private/PET生成CT/pictures84']\n",
      "0085: process image... ['/opt/data/private/PET生成CT/pictures85']\n",
      "0086: process image... ['/opt/data/private/PET生成CT/pictures86']\n",
      "0087: process image... ['/opt/data/private/PET生成CT/pictures87']\n",
      "0088: process image... ['/opt/data/private/PET生成CT/pictures88']\n",
      "0089: process image... ['/opt/data/private/PET生成CT/pictures89']\n",
      "0090: process image... ['/opt/data/private/PET生成CT/pictures90']\n",
      "0091: process image... ['/opt/data/private/PET生成CT/pictures91']\n",
      "0092: process image... ['/opt/data/private/PET生成CT/pictures92']\n",
      "0093: process image... ['/opt/data/private/PET生成CT/pictures93']\n",
      "0094: process image... ['/opt/data/private/PET生成CT/pictures94']\n",
      "0095: process image... ['/opt/data/private/PET生成CT/pictures95']\n",
      "0096: process image... ['/opt/data/private/PET生成CT/pictures96']\n",
      "0097: process image... ['/opt/data/private/PET生成CT/pictures97']\n",
      "0098: process image... ['/opt/data/private/PET生成CT/pictures98']\n",
      "0099: process image... ['/opt/data/private/PET生成CT/pictures99']\n",
      "0100: process image... ['/opt/data/private/PET生成CT/pictures100']\n",
      "0101: process image... ['/opt/data/private/PET生成CT/pictures101']\n",
      "0102: process image... ['/opt/data/private/PET生成CT/pictures102']\n",
      "0103: process image... ['/opt/data/private/PET生成CT/pictures103']\n",
      "0104: process image... ['/opt/data/private/PET生成CT/pictures104']\n",
      "0105: process image... ['/opt/data/private/PET生成CT/pictures105']\n",
      "0106: process image... ['/opt/data/private/PET生成CT/pictures106']\n",
      "0107: process image... ['/opt/data/private/PET生成CT/pictures107']\n",
      "0108: process image... ['/opt/data/private/PET生成CT/pictures108']\n",
      "0109: process image... ['/opt/data/private/PET生成CT/pictures109']\n",
      "0110: process image... ['/opt/data/private/PET生成CT/pictures110']\n",
      "0111: process image... ['/opt/data/private/PET生成CT/pictures111']\n",
      "0112: process image... ['/opt/data/private/PET生成CT/pictures112']\n",
      "0113: process image... ['/opt/data/private/PET生成CT/pictures113']\n",
      "0114: process image... ['/opt/data/private/PET生成CT/pictures114']\n",
      "0115: process image... ['/opt/data/private/PET生成CT/pictures115']\n",
      "0116: process image... ['/opt/data/private/PET生成CT/pictures116']\n",
      "0117: process image... ['/opt/data/private/PET生成CT/pictures117']\n",
      "0118: process image... ['/opt/data/private/PET生成CT/pictures118']\n",
      "0119: process image... ['/opt/data/private/PET生成CT/pictures119']\n",
      "0120: process image... ['/opt/data/private/PET生成CT/pictures120']\n",
      "0121: process image... ['/opt/data/private/PET生成CT/pictures121']\n",
      "0122: process image... ['/opt/data/private/PET生成CT/pictures122']\n",
      "0123: process image... ['/opt/data/private/PET生成CT/pictures123']\n",
      "0124: process image... ['/opt/data/private/PET生成CT/pictures124']\n",
      "0125: process image... ['/opt/data/private/PET生成CT/pictures125']\n",
      "0126: process image... ['/opt/data/private/PET生成CT/pictures126']\n",
      "0127: process image... ['/opt/data/private/PET生成CT/pictures127']\n",
      "0128: process image... ['/opt/data/private/PET生成CT/pictures128']\n",
      "0129: process image... ['/opt/data/private/PET生成CT/pictures129']\n",
      "0130: process image... ['/opt/data/private/PET生成CT/pictures130']\n",
      "0131: process image... ['/opt/data/private/PET生成CT/pictures131']\n",
      "0132: process image... ['/opt/data/private/PET生成CT/pictures132']\n",
      "0133: process image... ['/opt/data/private/PET生成CT/pictures133']\n",
      "0134: process image... ['/opt/data/private/PET生成CT/pictures134']\n",
      "0135: process image... ['/opt/data/private/PET生成CT/pictures135']\n",
      "0136: process image... ['/opt/data/private/PET生成CT/pictures136']\n",
      "0137: process image... ['/opt/data/private/PET生成CT/pictures137']\n",
      "0138: process image... ['/opt/data/private/PET生成CT/pictures138']\n",
      "0139: process image... ['/opt/data/private/PET生成CT/pictures139']\n",
      "0140: process image... ['/opt/data/private/PET生成CT/pictures140']\n",
      "0141: process image... ['/opt/data/private/PET生成CT/pictures141']\n",
      "0142: process image... ['/opt/data/private/PET生成CT/pictures142']\n",
      "0143: process image... ['/opt/data/private/PET生成CT/pictures143']\n",
      "0144: process image... ['/opt/data/private/PET生成CT/pictures144']\n",
      "0145: process image... ['/opt/data/private/PET生成CT/pictures145']\n",
      "0146: process image... ['/opt/data/private/PET生成CT/pictures146']\n",
      "0147: process image... ['/opt/data/private/PET生成CT/pictures147']\n",
      "0148: process image... ['/opt/data/private/PET生成CT/pictures148']\n",
      "0149: process image... ['/opt/data/private/PET生成CT/pictures149']\n",
      "0150: process image... ['/opt/data/private/PET生成CT/pictures150']\n",
      "0151: process image... ['/opt/data/private/PET生成CT/pictures151']\n",
      "0152: process image... ['/opt/data/private/PET生成CT/pictures152']\n",
      "0153: process image... ['/opt/data/private/PET生成CT/pictures153']\n",
      "0154: process image... ['/opt/data/private/PET生成CT/pictures154']\n",
      "0155: process image... ['/opt/data/private/PET生成CT/pictures155']\n",
      "0156: process image... ['/opt/data/private/PET生成CT/pictures156']\n",
      "0157: process image... ['/opt/data/private/PET生成CT/pictures157']\n",
      "0158: process image... ['/opt/data/private/PET生成CT/pictures158']\n",
      "0159: process image... ['/opt/data/private/PET生成CT/pictures159']\n",
      "0160: process image... ['/opt/data/private/PET生成CT/pictures160']\n",
      "0161: process image... ['/opt/data/private/PET生成CT/pictures161']\n",
      "0162: process image... ['/opt/data/private/PET生成CT/pictures162']\n",
      "0163: process image... ['/opt/data/private/PET生成CT/pictures163']\n",
      "0164: process image... ['/opt/data/private/PET生成CT/pictures164']\n",
      "0165: process image... ['/opt/data/private/PET生成CT/pictures165']\n",
      "0166: process image... ['/opt/data/private/PET生成CT/pictures166']\n",
      "0167: process image... ['/opt/data/private/PET生成CT/pictures167']\n",
      "0168: process image... ['/opt/data/private/PET生成CT/pictures168']\n",
      "0169: process image... ['/opt/data/private/PET生成CT/pictures169']\n",
      "0170: process image... ['/opt/data/private/PET生成CT/pictures170']\n",
      "0171: process image... ['/opt/data/private/PET生成CT/pictures171']\n",
      "0172: process image... ['/opt/data/private/PET生成CT/pictures172']\n",
      "0173: process image... ['/opt/data/private/PET生成CT/pictures173']\n",
      "0174: process image... ['/opt/data/private/PET生成CT/pictures174']\n",
      "0175: process image... ['/opt/data/private/PET生成CT/pictures175']\n",
      "0176: process image... ['/opt/data/private/PET生成CT/pictures176']\n",
      "0177: process image... ['/opt/data/private/PET生成CT/pictures177']\n",
      "0178: process image... ['/opt/data/private/PET生成CT/pictures178']\n",
      "0179: process image... ['/opt/data/private/PET生成CT/pictures179']\n",
      "0180: process image... ['/opt/data/private/PET生成CT/pictures180']\n",
      "0181: process image... ['/opt/data/private/PET生成CT/pictures181']\n",
      "0182: process image... ['/opt/data/private/PET生成CT/pictures182']\n",
      "0183: process image... ['/opt/data/private/PET生成CT/pictures183']\n",
      "0184: process image... ['/opt/data/private/PET生成CT/pictures184']\n",
      "0185: process image... ['/opt/data/private/PET生成CT/pictures185']\n",
      "0186: process image... ['/opt/data/private/PET生成CT/pictures186']\n",
      "0187: process image... ['/opt/data/private/PET生成CT/pictures187']\n",
      "0188: process image... ['/opt/data/private/PET生成CT/pictures188']\n",
      "0189: process image... ['/opt/data/private/PET生成CT/pictures189']\n",
      "0190: process image... ['/opt/data/private/PET生成CT/pictures190']\n",
      "0191: process image... ['/opt/data/private/PET生成CT/pictures191']\n",
      "0192: process image... ['/opt/data/private/PET生成CT/pictures192']\n",
      "0193: process image... ['/opt/data/private/PET生成CT/pictures193']\n",
      "0194: process image... ['/opt/data/private/PET生成CT/pictures194']\n",
      "0195: process image... ['/opt/data/private/PET生成CT/pictures195']\n",
      "0196: process image... ['/opt/data/private/PET生成CT/pictures196']\n",
      "0197: process image... ['/opt/data/private/PET生成CT/pictures197']\n",
      "0198: process image... ['/opt/data/private/PET生成CT/pictures198']\n",
      "0199: process image... ['/opt/data/private/PET生成CT/pictures199']\n",
      "0200: process image... ['/opt/data/private/PET生成CT/pictures200']\n",
      "0201: process image... ['/opt/data/private/PET生成CT/pictures201']\n",
      "0202: process image... ['/opt/data/private/PET生成CT/pictures202']\n",
      "0203: process image... ['/opt/data/private/PET生成CT/pictures203']\n",
      "0204: process image... ['/opt/data/private/PET生成CT/pictures204']\n",
      "0205: process image... ['/opt/data/private/PET生成CT/pictures205']\n",
      "0206: process image... ['/opt/data/private/PET生成CT/pictures206']\n",
      "0207: process image... ['/opt/data/private/PET生成CT/pictures207']\n",
      "0208: process image... ['/opt/data/private/PET生成CT/pictures208']\n",
      "0209: process image... ['/opt/data/private/PET生成CT/pictures209']\n",
      "0210: process image... ['/opt/data/private/PET生成CT/pictures210']\n",
      "0211: process image... ['/opt/data/private/PET生成CT/pictures211']\n",
      "0212: process image... ['/opt/data/private/PET生成CT/pictures212']\n",
      "0213: process image... ['/opt/data/private/PET生成CT/pictures213']\n",
      "0214: process image... ['/opt/data/private/PET生成CT/pictures214']\n",
      "0215: process image... ['/opt/data/private/PET生成CT/pictures215']\n",
      "0216: process image... ['/opt/data/private/PET生成CT/pictures216']\n",
      "0217: process image... ['/opt/data/private/PET生成CT/pictures217']\n",
      "0218: process image... ['/opt/data/private/PET生成CT/pictures218']\n",
      "0219: process image... ['/opt/data/private/PET生成CT/pictures219']\n",
      "0220: process image... ['/opt/data/private/PET生成CT/pictures220']\n",
      "0221: process image... ['/opt/data/private/PET生成CT/pictures221']\n",
      "0222: process image... ['/opt/data/private/PET生成CT/pictures222']\n",
      "0223: process image... ['/opt/data/private/PET生成CT/pictures223']\n",
      "0224: process image... ['/opt/data/private/PET生成CT/pictures224']\n",
      "0225: process image... ['/opt/data/private/PET生成CT/pictures225']\n",
      "0226: process image... ['/opt/data/private/PET生成CT/pictures226']\n",
      "0227: process image... ['/opt/data/private/PET生成CT/pictures227']\n",
      "0228: process image... ['/opt/data/private/PET生成CT/pictures228']\n",
      "0229: process image... ['/opt/data/private/PET生成CT/pictures229']\n",
      "0230: process image... ['/opt/data/private/PET生成CT/pictures230']\n",
      "0231: process image... ['/opt/data/private/PET生成CT/pictures231']\n",
      "0232: process image... ['/opt/data/private/PET生成CT/pictures232']\n",
      "0233: process image... ['/opt/data/private/PET生成CT/pictures233']\n",
      "0234: process image... ['/opt/data/private/PET生成CT/pictures234']\n",
      "0235: process image... ['/opt/data/private/PET生成CT/pictures235']\n",
      "0236: process image... ['/opt/data/private/PET生成CT/pictures236']\n",
      "0237: process image... ['/opt/data/private/PET生成CT/pictures237']\n",
      "0238: process image... ['/opt/data/private/PET生成CT/pictures238']\n",
      "0239: process image... ['/opt/data/private/PET生成CT/pictures239']\n",
      "0240: process image... ['/opt/data/private/PET生成CT/pictures240']\n",
      "0241: process image... ['/opt/data/private/PET生成CT/pictures241']\n",
      "0242: process image... ['/opt/data/private/PET生成CT/pictures242']\n",
      "0243: process image... ['/opt/data/private/PET生成CT/pictures243']\n",
      "0244: process image... ['/opt/data/private/PET生成CT/pictures244']\n",
      "0245: process image... ['/opt/data/private/PET生成CT/pictures245']\n",
      "0246: process image... ['/opt/data/private/PET生成CT/pictures246']\n",
      "0247: process image... ['/opt/data/private/PET生成CT/pictures247']\n",
      "0248: process image... ['/opt/data/private/PET生成CT/pictures248']\n",
      "0249: process image... ['/opt/data/private/PET生成CT/pictures249']\n",
      "0250: process image... ['/opt/data/private/PET生成CT/pictures250']\n",
      "0251: process image... ['/opt/data/private/PET生成CT/pictures251']\n",
      "0252: process image... ['/opt/data/private/PET生成CT/pictures252']\n",
      "0253: process image... ['/opt/data/private/PET生成CT/pictures253']\n",
      "0254: process image... ['/opt/data/private/PET生成CT/pictures254']\n",
      "0255: process image... ['/opt/data/private/PET生成CT/pictures255']\n",
      "0256: process image... ['/opt/data/private/PET生成CT/pictures256']\n",
      "0257: process image... ['/opt/data/private/PET生成CT/pictures257']\n",
      "0258: process image... ['/opt/data/private/PET生成CT/pictures258']\n",
      "0259: process image... ['/opt/data/private/PET生成CT/pictures259']\n",
      "0260: process image... ['/opt/data/private/PET生成CT/pictures260']\n",
      "0261: process image... ['/opt/data/private/PET生成CT/pictures261']\n",
      "0262: process image... ['/opt/data/private/PET生成CT/pictures262']\n",
      "0263: process image... ['/opt/data/private/PET生成CT/pictures263']\n",
      "NIfTI 文件已保存：ct_real.nii.gz 和 ct_fake.nii.gz\n"
     ]
    }
   ],
   "source": [
    "model = create_model(opt)\n",
    "data_loader = CreateDataLoader2(opt)\n",
    "dataset = data_loader.load_data()\n",
    "\n",
    "# create website\n",
    "web_dir = os.path.join(opt.results_dir, opt.name, '%s_%s' % (opt.phase, opt.which_epoch))\n",
    "ct_real = np.zeros((264, 256, 256))\n",
    "ct_fake = np.zeros((264, 256, 256))\n",
    "\n",
    "for i, data in enumerate(dataset):\n",
    "    if i >= opt.how_many:\n",
    "        break\n",
    "    model.set_input(data)\n",
    "    model.test()      \n",
    "    visuals = model.get_current_visuals()\n",
    "    img_path = model.get_image_paths()\n",
    "    img_path[0]=img_path[0]+str(i)\n",
    "    print('%04d: process image... %s' % (i, img_path))\n",
    "\n",
    "    im ,im_faked= back_images(i,visuals, img_path, CTmax,aspect_ratio=opt.aspect_ratio)    \n",
    "    ct_real[i,:, :] = im[:,:,0]\n",
    "    ct_fake[i,:, :] = im_faked[:,:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_real = np.transpose(ct_real, (0, 2, 1))\n",
    "ct_fake = np.transpose(ct_fake, (0, 2, 1))\n",
    "\n",
    "ct_real = sitk.GetImageFromArray(ct_real)\n",
    "ct_fake = sitk.GetImageFromArray(ct_fake)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(opt)\n",
    "\n",
    "opt.name = 'resnet_9blocks'\n",
    "opt.which_model_netG = 'resnet_9blocks'\n",
    "model2 = create_model(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/data/private/PET生成CT/pictures/axial/test/test.pkl', 'rb') as f:\n",
    "    axial_ct = pickle.load(f)\n",
    "    axial_pet = pickle.load(f)\n",
    "\n",
    "opt.dataroot='/opt/data/private/PET生成CT/pictures/axial'\n",
    "data_loader = CreateDataLoader2(opt)\n",
    "dataset = data_loader.load_data()\n",
    "visuals_axial = np.zeros([256,256,len(data_loader)])\n",
    "visuals_axial2 = np.zeros([256,256,len(data_loader)])\n",
    "\n",
    "for i, data in enumerate(dataset):\n",
    "    if i >= opt.how_many:\n",
    "        break\n",
    "    model.set_input(data)\n",
    "    model.test()      \n",
    "    visuals = model.get_current_visuals()\n",
    "\n",
    "    model2.set_input(data)\n",
    "    model2.test()      \n",
    "    visuals2 = model2.get_current_visuals()\n",
    "\n",
    "    img_path = model.get_image_paths()\n",
    "    img_path[0]=img_path[0]+'_'+str(i)\n",
    "    print('%04d: process image... %s' % (i, img_path))\n",
    "    visuals_axial[:,:,i] = (visuals['fake_B'].squeeze(2))\n",
    "    visuals_axial[:,:,i] = (visuals_axial[:,:,i] - (0)) / 255 * (CTmax[i] - (-1024)) + -1024\n",
    "\n",
    "    visuals_axial2[:,:,i] = (visuals2['fake_B'].squeeze(2))\n",
    "    visuals_axial2[:,:,i] = (visuals_axial2[:,:,i] - (0)) / 255 * (CTmax[i] - (-1024)) + -1024\n",
    "\n",
    "    axial_ct[:,:,i]  = (axial_ct[:,:,i] - (-1)) / 2 * (CTmax[i] - (-1024)) + -1024\n",
    "    axial_pet[:,:,i] = (axial_pet[:,:,i] - (-1)) / 2 * (PETmax[i] - (0)) + 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# picpath ='/opt/data/private/PET生成CT/pictures/'\n",
    "# sitkImage1 = sitk.GetImageFromArray(np.transpose(axial_ct[:,:,1:-1],(2,0,1)))\n",
    "# sitk.WriteImage(sitkImage1,os.path.join(picpath,picpath+'1.nii.gz'))\n",
    "\n",
    "# sitkImage2 = sitk.GetImageFromArray(np.transpose(axial_pet[:,:,1:-1],(2,0,1)))\n",
    "# sitk.WriteImage(sitkImage2,os.path.join(picpath,picpath+'2.nii.gz'))\n",
    "\n",
    "# sitkImage3 = sitk.GetImageFromArray(np.transpose(visuals_axial,(2,0,1)))\n",
    "# sitk.WriteImage(sitkImage3,os.path.join(picpath,picpath+'3.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pics2nii(picpath,niipath):\n",
    "    files = os.listdir(picpath)\n",
    "    niiarr=np.zeros((len(files),600,800,3))\n",
    "\n",
    "    for i in range(len(files)):\n",
    "        img=sitk.ReadImage(os.path.join(picpath,files[i]))\n",
    "        imgarr = sitk.GetArrayFromImage(img)\n",
    "        niiarr[i,:,:,:]=imgarr\n",
    "        \n",
    "    niiimg=sitk.GetImageFromArray(np.uint8(niiarr))\n",
    "\n",
    "    sitk.WriteImage(niiimg,os.path.join(picpath,picpath+'.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,((ax1, ax2, ax3, ax4), (ax5, ax6, ax7, ax8)) = plt.subplots(2,4, figsize=(10, 7))\n",
    "im1 = ax1.imshow(np.rot90(axial_pet[128,:,:]), cmap=plt.cm.RdBu_r)#plt.cm.RdBu\n",
    "ax1.set_title('Real PET(coronal)')\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "\n",
    "\n",
    "im2 = ax2.imshow(np.rot90(axial_pet[:,128,:]), cmap=plt.cm.RdBu_r)#plt.cm.RdBu\n",
    "ax2.set_title('Real PET(sagittal)')\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "ax2.axvline(x=128, color='yellow', linestyle='--', linewidth=3)\n",
    "#for spine in ax2.spines.values():\n",
    "#   spine.set_visible(False)\n",
    "\n",
    "im3 = ax3.imshow(np.rot90(axial_ct[128,:,:]), cmap='gray')  \n",
    "ax3.set_title('Real CT(coronal)')\n",
    "ax3.set_xticks([])\n",
    "ax3.set_yticks([])\n",
    "\n",
    "im4 = ax4.imshow(np.rot90(axial_ct[:,128,:]), cmap='gray')  \n",
    "\n",
    "ax4.set_title('Real CT(sagittal)')\n",
    "ax4.set_xticks([])\n",
    "ax4.set_yticks([])\n",
    "#for spine in ax3.spines.values():\n",
    "#    spine.set_visible(False)\n",
    "\n",
    "plt.subplots_adjust(left=0.1, right=0.95, wspace=0)  # 调整子图和色条之间的间距\n",
    "\n",
    "\n",
    "im5 = ax5.imshow(np.rot90(visuals_axial[128,:,:]), cmap='gray')\n",
    "ax5.set_title('Synthetic CT(coronal,ours)')\n",
    "ax5.set_xticks([])\n",
    "ax5.set_yticks([])\n",
    "\n",
    "#cv2.normalize(visuals_axial[:,128,:], None, alpha=-1,beta=1,norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "im6 = ax6.imshow(np.rot90(visuals_axial[:,128,:]), cmap='gray')\n",
    "ax6.set_title('Synthetic CT(sagittal,ours)')\n",
    "ax6.set_xticks([])\n",
    "ax6.set_yticks([])\n",
    "\n",
    "im7 = ax7.imshow(np.rot90(visuals_axial2[128,:,:]), cmap='gray')\n",
    "ax7.set_title('Synthetic CT(coronal,pGAN)')\n",
    "ax7.set_xticks([])\n",
    "ax7.set_yticks([])\n",
    "\n",
    "im8 = ax8.imshow(np.rot90(visuals_axial2[:,128,:]), cmap='gray')\n",
    "ax8.set_title('Synthetic CT(sagittal,pGAN)')\n",
    "ax8.set_xticks([])\n",
    "ax8.set_yticks([])\n",
    "\n",
    "# cbar_ax = fig.add_axes([-0.01, 0.655, 0.02, 0.22]) # [left, bottom, width, height]\n",
    "# fig.colorbar(im1, cax=cbar_ax)\n",
    "# cbar_ax_jet = fig.add_axes([-0.01, 0.385, 0.02, 0.22]) \n",
    "# fig.colorbar(im3, cax=cbar_ax_jet)  \n",
    "# cbar_ax_jet = fig.add_axes([-0.01, 0.115, 0.02, 0.22]) \n",
    "# fig.colorbar(im5, cax=cbar_ax_jet) \n",
    "\n",
    "plt.subplots_adjust(left=0.1, right=1.2, wspace=0)  # 调整子图和色条之间的间距\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(axial_ct[128,128,:].flatten(), linestyle='--', color='#b235e6',label='CT')\n",
    "#plt.plot(axial_pet[128,128,:].flatten(), linestyle='--', color='#7cd6cf',label='PET')\n",
    "plt.plot((visuals_axial[128,128,:]),\n",
    "    linestyle='-', color='red',label='Synthetic CT(ours)')\n",
    "plt.plot((visuals_axial2[128,128,:]),\n",
    "    linestyle='-', color='#70ad47',label='Synthetic CT(pgan)')\n",
    "\n",
    "plt.title('Pixel Value Distribution')\n",
    "plt.xlabel('Pixel Index')\n",
    "plt.ylabel('Pixel Value')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = 'fake_PET_coronal.png' \n",
    "save_path = os.path.join(img_dir, image_name)\n",
    "\n",
    "image_pil = Image.fromarray(visuals_numpy[128,:,:].astype(np.uint8))\n",
    "image_pil.save(save_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
